package org.example.app.core

import ai.koog.prompt.dsl.prompt
import ai.koog.prompt.executor.llms.all.simpleOpenAIExecutor
import ai.koog.prompt.executor.clients.openai.OpenAIModels
import ai.koog.prompt.executor.model.PromptExecutor
import ai.koog.prompt.message.Message
import ai.koog.prompt.structure.StructureFixingParser
import ai.koog.prompt.structure.executeStructured
import kotlinx.coroutines.runBlocking
import kotlinx.serialization.Serializable
import java.nio.file.Files
import java.nio.file.Path
import kotlin.io.path.writeText
import org.example.app.intermediate.*
import org.example.app.core.*
/**
 * Core orchestrator:
 * 1) Validate checklist is fully confirmed.
 * 2) Derive ChecklistSpec from checklist.snapshot() (no need to modify checklist class).
 * 3) Ask LLM to pick a model family category (cluster category only).
 * 4) Ask LLM to pick a concrete model under that family (library + model id).
 * 5) Ask LLM to generate model.py and test.py.
 * 6) Execute test.py; if failed, feed error back to regenerate model.py and retry.
 */
class MlAutoGenCore(
    private val executor: PromptExecutor,
    private val llmModel: ai.koog.prompt.llm.LLModel = OpenAIModels.Chat.GPT4oMini,
    private val fixerModel: ai.koog.prompt.llm.LLModel = OpenAIModels.Chat.GPT4o
) {
    companion object {
        /**
         * Python-side interface contract between model.py and test.py.
         * Keep this stable so your test agent can always validate generated code.
         */
        const val MODEL_API_CONTRACT: String = """
- File: model.py
- Must define:
  1) class ModelWrapper:
       - __init__(self, config: dict | None = None)
       - fit(self, X, y=None) -> self
       - predict(self, X)
       - (optional) save(self, path: str)
       - (optional) @classmethod load(cls, path: str) -> "ModelWrapper"
  2) def build_model(config: dict | None = None) -> ModelWrapper

Notes:
- X can be numpy arrays / torch tensors / list[str] depending on input type.
- predict(...) should return a sensible output for the declared output type.
"""
    }

    /**
     * The only thing we assume about your checklist class:
     * - checklist.check(): Boolean
     * - checklist.snapshot(): String
     */
    interface ChecklistLike {
        fun check(): Boolean
        fun snapshot(): String
    }

    @Serializable
    data class ModelFamilyPick(
        val family: ModelFamilyCategory,
        val shortRationale: String
    )

    @Serializable
    data class ConcreteModelChoice(
        val library: String,        // e.g., "sklearn", "torch", "xgboost"
        val modelId: String,         // e.g., "LogisticRegression", "resnet18", "XGBClassifier"
        val extraDependencies: List<String> = emptyList(),
        val shortRationale: String
    )

    /**
     * Minimal spec extracted from checklist.snapshot().
     * These enum names MUST match your earlier enums (the checklist file you already made).
     *
     * If your enums live in another package, just fix the imports or qualify the names.
     */
    data class ChecklistSpec(
        val inputType: InputType,
        val outputType: OutputType,
        val trainingType: TrainingType,
        val splitStrategy: SplitStrategy,
        val metric: Metric,
        val dataPath: String
    )

    /**
     * Parse the snapshot() string (generated by your checklist) and reconstruct the values.
     * This avoids changing your existing checklist implementation.
     */
    fun specFromSnapshot(snapshot: String): ChecklistSpec {
        fun findValue(label: String): String {
            val regex = Regex("""^\s*$label\s*:\s*(.+?)\s*$""", RegexOption.MULTILINE)
            val m = regex.find(snapshot) ?: error("Cannot find '$label' in checklist.snapshot()")
            return m.groupValues[1].trim()
        }

        // Remove trailing status like "(Confirmed)" / "(Not confirmed)" / "(Not set)"
        fun stripTrailingStatus(raw: String): String =
            raw.replace(Regex("""\s*\([^()]*\)\s*$"""), "").trim()

        // Handle cases like "CUSTOM(desc...)" by taking only the enum name before '('
        fun enumName(raw: String): String {
            val v = stripTrailingStatus(raw)
            val idx = v.indexOf('(')
            return if (idx >= 0) v.substring(0, idx).trim() else v
        }

        val inputType = InputType.valueOf(enumName(findValue("Input type")))
        val outputType = OutputType.valueOf(enumName(findValue("Output type")))
        val trainingType = TrainingType.valueOf(enumName(findValue("Training type")))
        val splitStrategy = SplitStrategy.valueOf(enumName(findValue("Split strategy")))
        val metric = Metric.valueOf(enumName(findValue("Metric")))
        val dataPath = stripTrailingStatus(findValue("Data path"))

        return ChecklistSpec(
            inputType = inputType,
            outputType = outputType,
            trainingType = trainingType,
            splitStrategy = splitStrategy,
            metric = metric,
            dataPath = dataPath
        )
    }

    /**
     * Ask LLM to choose a model family category (cluster category only).
     */
    suspend fun pickModelFamily(spec: ChecklistSpec): ModelFamilyPick {
        val fixingParser = StructureFixingParser(model = fixerModel, retries = 2)

        val p = prompt("pick-model-family") {
            system(
                """
You are a pragmatic ML architect.
Pick ONLY ONE model family category from the given enum based on the task spec.
Keep rationale short (1-2 sentences). No extra text outside structured output.
                """.trimIndent()
            )
            user(
                """
Task spec:
- inputType = ${spec.inputType}
- outputType = ${spec.outputType}
- trainingType = ${spec.trainingType}
- splitStrategy = ${spec.splitStrategy}
- metric = ${spec.metric}

Candidates:
- LINEAR_BASELINE
- TREE_BOOSTING
- CNN_VISION
- TRANSFORMER_TEXT
- SEQUENCE_MODEL
- CLUSTERING_UNSUPERVISED
- RL_POLICY
                """.trimIndent()
            )
        }

        val result = executor.executeStructured<ModelFamilyPick>(
            prompt = p,
            model = llmModel,
            fixingParser = fixingParser
        )
        return result.getOrThrow().data
    }

    /**
     * Ask LLM to choose a concrete model under the picked family.
     */
    suspend fun pickConcreteModel(spec: ChecklistSpec, family: ModelFamilyCategory): ConcreteModelChoice {
        val fixingParser = StructureFixingParser(model = fixerModel, retries = 2)

        val p = prompt("pick-concrete-model") {
            system(
                """
You are a senior ML engineer.
Choose a concrete model implementation under the given family.
Return library + modelId (identifier), plus any extra dependencies.
Prefer widely available libraries; avoid exotic dependencies unless necessary.
No extra text outside structured output.
                """.trimIndent()
            )
            user(
                """
Task spec:
- inputType = ${spec.inputType}
- outputType = ${spec.outputType}
- trainingType = ${spec.trainingType}
- metric = ${spec.metric}
- family = $family

Examples of acceptable outputs:
- library="sklearn", modelId="LogisticRegression"
- library="sklearn", modelId="RandomForestClassifier"
- library="xgboost", modelId="XGBRegressor"
- library="torch", modelId="resnet18"
- library="torch", modelId="small_mlp"

Now pick one.
                """.trimIndent()
            )
        }

        val result = executor.executeStructured<ConcreteModelChoice>(
            prompt = p,
            model = llmModel,
            fixingParser = fixingParser
        )
        return result.getOrThrow().data
    }

    /**
     * Build model + test, run tests, retry regeneration on failure.
     */
    suspend fun run(
        checklist: ChecklistLike,
        workDir: Path,
        maxModelRetries: Int = 5
    ): PipelineResult {
        if (!checklist.check()) {
            return PipelineResult.Failed(
                reason = "Checklist is not fully confirmed.",
                checklistSnapshot = checklist.snapshot()
            )
        }

        val spec = specFromSnapshot(checklist.snapshot())
        Files.createDirectories(workDir)

        val familyPick = pickModelFamily(spec)
        val concrete = pickConcreteModel(spec, familyPick.family)

        val testPy = TestGenerator(executor, llmModel).generateTestPy(spec, MODEL_API_CONTRACT)
        val testPath = workDir.resolve("test.py")
        testPath.writeText(testPy)

        val pythonRunner = PythonRunner()

        // NEW: dependency manager + installed set
        val depManager = PythonDependencyManager(
            executor = executor,
            llmModel = llmModel,
            fixerModel = fixerModel
        )
        val installedDeps = mutableSetOf<String>()

        // NEW: pre-install what the picker already suggested (if any)
        if (concrete.extraDependencies.isNotEmpty()) {
            val pre = concrete.extraDependencies.filter { it.isNotBlank() }.distinct()
            val r = depManager.pipInstall(pre, workDir)
            if (r.exitCode == 0) installedDeps.addAll(pre)
            // if pip fails, we don't hard-fail here; next loop can still attempt LLM inference based on error output
        }

        var lastErr: String? = null
        var lastModelPy: String? = null

        repeat(maxModelRetries) { attemptIdx ->
            val modelPy = ModelGenerator(executor, llmModel).generateModelPy(
                spec = spec,
                family = familyPick.family,
                concrete = concrete,
                contract = MODEL_API_CONTRACT,
                previousModelPy = lastModelPy,
                lastError = lastErr
            )
            val modelPath = workDir.resolve("model.py")
            modelPath.writeText(modelPy)

            // --- Run test once ---
            var runResult = pythonRunner.runTest(workDir = workDir, testFileName = "test.py")

            // NEW: after each run (success/failure), ask LLM to infer deps, then pip install missing ones
            suspend fun inferAndInstallIfNeeded(): Boolean {
                val plan = depManager.proposeDependencies(
                    spec = spec,
                    family = familyPick.family,
                    concrete = concrete,
                    modelPy = modelPy,
                    testPy = testPy,
                    lastStdout = runResult.stdout,
                    lastStderr = runResult.stderr
                )

                val toInstall = plan.pipPackages
                    .map { it.trim() }
                    .filter { it.isNotBlank() }
                    .filterNot { installedDeps.contains(it) }
                    .distinct()

                if (toInstall.isEmpty()) return false

                val pipRes = depManager.pipInstall(toInstall, workDir)
                if (pipRes.exitCode == 0) {
                    installedDeps.addAll(toInstall)
                    return true
                }

                // If pip failed, append pip error into lastErr so the next regeneration sees it.
                lastErr = buildString {
                    appendLine(runResult.stderr.ifBlank { runResult.stdout })
                    appendLine()
                    appendLine("pip install failed:")
                    appendLine(pipRes.stderr.ifBlank { pipRes.stdout })
                }.trim()

                return false
            }

            // Try install deps inferred from this run, then (if installed) rerun tests ONCE.
            val installedSomething = inferAndInstallIfNeeded()
            if (installedSomething) {
                runResult = pythonRunner.runTest(workDir = workDir, testFileName = "test.py")

                // (Optional but aligns with your request: "每次跑完都识别依赖")
                // Do one more inference pass after rerun; typically returns empty list.
                inferAndInstallIfNeeded()
            }

            if (runResult.exitCode == 0) {
                return PipelineResult.Success(
                    workDir = workDir.toString(),
                    family = familyPick,
                    concrete = concrete,
                    modelPy = modelPy,
                    testPy = testPy,
                    stdout = runResult.stdout,
                    stderr = runResult.stderr
                )
            }

            lastErr = runResult.stderr.ifBlank { runResult.stdout }
            lastModelPy = modelPy
        }

        return PipelineResult.Failed(
            reason = "model.py failed tests after $maxModelRetries retries.",
            checklistSnapshot = checklist.snapshot(),
            lastError = lastErr
        )
    }
}

/**
 * Pipeline result types.
 */
sealed class PipelineResult {
    data class Success(
        val workDir: String,
        val family: MlAutoGenCore.ModelFamilyPick,
        val concrete: MlAutoGenCore.ConcreteModelChoice,
        val modelPy: String,
        val testPy: String,
        val stdout: String,
        val stderr: String
    ) : PipelineResult()

    data class Failed(
        val reason: String,
        val checklistSnapshot: String,
        val lastError: String? = null
    ) : PipelineResult()
}

/**
 * Minimal demo entrypoint.
 * Replace DummyChecklist with your real checklist class adapter.
 */
fun main() = runBlocking {
    val apiKey = System.getenv("OPENAI_API_KEY") ?: error("Missing OPENAI_API_KEY env var")

    // Koog prompt executor (OpenAI example)
    val executor = simpleOpenAIExecutor(apiKey) // provided by prompt-executor-llms-all
    executor.use {
        val core = MlAutoGenCore(executor = it)

        val checklist = DummyChecklist(
            snapshotText = """
Input type: IMAGE
Output type: CATEGORY
Training type: SUPERVISED
Split strategy: HOLDOUT
Metric: ACCURACY
Data path: /tmp/data
            """.trimIndent(),
            ok = true
        )

        val result = core.run(
            checklist = checklist,
            workDir = Path.of("generated_ml")
        )

        println(result)
    }
}

/**
 * Dummy checklist adapter for quick local testing.
 * In your project, adapt your real checklist to MlAutoGenCore.ChecklistLike.
 */
data class DummyChecklist(
    private val snapshotText: String,
    private val ok: Boolean
) : MlAutoGenCore.ChecklistLike {
    override fun check(): Boolean = ok
    override fun snapshot(): String = snapshotText
}